{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## LangChain: Memory\n",
    "* ConversationBufferMemory\n",
    "* ConversationBufferWindowMemory\n",
    "* ConversationTokenBufferMemory\n",
    "* ConversationSummaryMemory"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "eba420733059e971"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import datetime\n",
    "import json\n",
    "import os\n",
    "\n",
    "import openai\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "import warnings\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.chains import ConversationChain\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.memory import ConversationBufferWindowMemory\n",
    "from langchain.memory import ConversationTokenBufferMemory\n",
    "from langchain.memory import ConversationSummaryBufferMemory\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.output_parsers import ResponseSchema\n",
    "from langchain.output_parsers import StructuredOutputParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "_ = load_dotenv(find_dotenv())  # read local .env file\n",
    "openai.api_key = os.environ['OPENAI_API_KEY_FOUR']\n",
    "# account for deprecation of LLM model\n",
    "\n",
    "# Get the current date\n",
    "current_date = datetime.datetime.now().date()\n",
    "\n",
    "# Define the date after which the model should be set to \"gpt-3.5-turbo\"\n",
    "target_date = datetime.date(2024, 6, 12)\n",
    "\n",
    "# Set the model variable based on the current date\n",
    "if current_date > target_date:\n",
    "    llm_model = \"gpt-3.5-turbo\"\n",
    "else:\n",
    "    llm_model = \"gpt-3.5-turbo-0301\"\n",
    "# print(openai.api_key)\n",
    "warnings.filterwarnings('ignore')"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "30ee818a4865e3ab"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(temperature=0.0, model=llm_model)\n",
    "llm.openai_api_key = openai.api_key\n",
    "memory = ConversationBufferMemory()\n",
    "conversation = ConversationChain(\n",
    "    llm=llm,\n",
    "    memory=memory,\n",
    "    verbose=True\n",
    ")\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "72bfc254c609a28d"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "conversation.predict(input=\"Hi, my name is Andrew\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e7053901058769c0"
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "aa1af954e407d9e0"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "conversation.predict(input=\"What is 1+1?\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c0cb8cc5d80ee28e"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "conversation.predict(input=\"What was my name\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f57324968be38983"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(memory.buffer)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "18348390155e505"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(memory.load_memory_variables({}))"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d66a2a843fd9d399"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "memory = ConversationBufferMemory()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8da67fb33b811828"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "memory.save_context({\"input\": \"Hi\"},\n",
    "                    {\"output\": \"What's up\"})\n",
    "print(memory.buffer)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6dc31c306083650"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "memory.load_memory_variables({})"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3682e55ae7272b7a"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "memory.save_context({\"input\": \"Not much, just hanging\"},\n",
    "                    {\"output\": \"Cool\"})"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "965c07a06673ee4"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "memory.load_memory_variables({})"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "aa2cbe66f8818069"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## ConversationBufferWindowMemory"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "766bd97e45ba33bf"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "memory = ConversationBufferWindowMemory(k=1)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "10f6a91f1faad07a"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "memory.save_context({\"input\": \"Hi\"},\n",
    "                    {\"output\": \"What's up\"})\n",
    "memory.save_context({\"input\": \"Not much, just hanging\"},\n",
    "                    {\"output\": \"Cool\"})"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ab74734565cfa358"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "memory.load_memory_variables({})"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d91e5307bf977e31"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(temperature=0.0, model=llm_model)\n",
    "llm.openai_api_key = openai.api_key\n",
    "memory = ConversationBufferWindowMemory(k=1)\n",
    "conversation = ConversationChain(\n",
    "    llm=llm,\n",
    "    memory=memory,\n",
    "    verbose=True\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6cf55a22089f45dc"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "conversation.predict(input=\"Hi, my name is Andrew\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "445b6f67493c89bd"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "conversation.predict(input=\"What is 1+1?\")\n",
    "# Model will remember just last line ( k=1) of the conversation."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1d017f292ffd5ea5"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "conversation.predict(input=\"What is my name?\")\n",
    "# Look carefully of the current conversation in ConversationChain.\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "98ab752da81af96a"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## ConversationBufferTokenMemory"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "64525d7a85befb3e"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(temperature=0.0, model=llm_model)\n",
    "llm.openai_api_key = openai.api_key"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6d9de1151df6f61f"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# !pip install tiktoken"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4f4bb5e22886d02a"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "memory = ConversationTokenBufferMemory(llm=llm, max_token_limit=30)\n",
    "memory.save_context({\"input\": \"AI is what?!\"},\n",
    "                    {\"output\": \"Amazing!\"})\n",
    "memory.save_context({\"input\": \"Backpropagation is what?\"},\n",
    "                    {\"output\": \"Beautiful!\"})\n",
    "memory.save_context({\"input\": \"Chatbots are what?\"},\n",
    "                    {\"output\": \"Charming!\"})"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "60c1a25c87936ec8"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "memory.load_memory_variables({})"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "10abbbfdf1a5dd01"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## ConversationSummaryMemory"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "59bceffc5a5be643"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# create a long string\n",
    "schedule = \"There is a meeting at 8am with your product team. \\\n",
    "You will need your powerpoint presentation prepared. \\\n",
    "9am-12pm have time to work on your LangChain \\\n",
    "project which will go quickly because Langchain is such a powerful tool. \\\n",
    "At Noon, lunch at the italian resturant with a customer who is driving \\\n",
    "from over an hour away to meet you to understand the latest in AI. \\\n",
    "Be sure to bring your laptop to show the latest LLM demo.\"\n",
    "\n",
    "memory = ConversationSummaryBufferMemory(llm=llm, max_token_limit=100)\n",
    "# llm.openai_api_key = openai.api_key\n",
    "memory.save_context({\"input\": \"Hello\"}, {\"output\": \"What's up\"})\n",
    "memory.save_context({\"input\": \"Not much, just hanging\"},\n",
    "                    {\"output\": \"Cool\"})\n",
    "memory.save_context({\"input\": \"What is on the schedule today?\"},\n",
    "                    {\"output\": f\"{schedule}\"})"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a8f96e1513a2e60c"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "memory.load_memory_variables({})"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4c334017a1f66423"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "conversation = ConversationChain(\n",
    "    llm=llm,\n",
    "    memory=memory,\n",
    "    verbose=True\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "48423014f18583c"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "conversation.predict(input=\"What would be a good demo to show?\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "dd7ee56522fd4012"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "memory.load_memory_variables({})"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "73234f2b2fa05a40"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "e0f6a7e56314a9ae"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
